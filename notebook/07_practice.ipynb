{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1개의 열만 고정하고 나머지 열을 행으로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pew = pd.read_csv('../data/pew.csv')\n",
    "print(pew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pew.iloc[:, 0:6])\n",
    "\n",
    "#                    religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k\n",
    "# 0                  Agnostic     27       34       60       81       76\n",
    "# 1                   Atheist     12       27       37       52       35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pew_long = pd.melt(pew, id_vars='religion')\n",
    "print(pew_long)\n",
    "\n",
    "#                     religion            variable  value\n",
    "# 0                   Agnostic               <$10k     27\n",
    "# ...r5\n",
    "# 17              Unaffiliated               <$10k    217\n",
    "# 18                  Agnostic             $10-20k     34\n",
    "# 19                   Atheist             $10-20k     27\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 variable, value열의 이름을 바꾸는 방법\n",
    "pew_long = pd.melt(pew, id_vars='religion', var_name='income', value_name='count')\n",
    "print(pew_long.head())\n",
    "\n",
    "#              religion income  count\n",
    "# 0            Agnostic  <$10k     27\n",
    "# 1             Atheist  <$10k     12\n",
    "# 2            Buddhist  <$10k     27\n",
    "# 3            Catholic  <$10k    418\n",
    "# 4  Don’t know/refused  <$10k     15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2개 이상의 열을 고정하고 나머지 열을 행으로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard = pd.read_csv('../data/billboard.csv')\n",
    "print(billboard.iloc[0:5, 0:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_long = pd.melt(billboard, id_vars=['year', 'artist', 'track', 'time', 'date.entered'], \n",
    "                         var_name='week', value_name='rating')\n",
    "print(billboard_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# ebola 데이터 집합 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola = pd.read_csv('../data/country_timeseries.csv')\n",
    "print(ebola.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ebola.iloc[:5, [1, 2, 3, 4, 10, 11]])\n",
    "\n",
    "#    Day  Cases_Guinea  Cases_Liberia  Cases_SierraLeone  Deaths_Guinea  \\\n",
    "# 0  289        2776.0            NaN            10030.0         1786.0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola_long = pd.melt(ebola, id_vars=['Date', 'Day'])\n",
    "print(ebola_long.head())\n",
    "\n",
    "#          Date  Day      variable   value\n",
    "# 0    1/5/2015  289  Cases_Guinea  2776.0\n",
    "# 1    1/4/2015  288  Cases_Guinea  2775.0\n",
    "# 2    1/3/2015  287  Cases_Guinea  2769.0\n",
    "# 3    1/2/2015  286  Cases_Guinea     NaN\n",
    "# 4  12/31/2014  284  Cases_Guinea  2730.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 열 이름 나누고 데이터 프레임에 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_split = ebola_long.variable.str.split('_')\n",
    "print(variable_split[:5])\n",
    "\n",
    "# 0    [Cases, Guinea]\n",
    "# 1    [Cases, Guinea]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(variable_split))  # Series\n",
    "print(type(variable_split[0]))  # list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_values = variable_split.str.get(0)  # 상태\n",
    "country_values = variable_split.str.get(1)  # 나라\n",
    "print(status_values[:5])  # 0    Cases\n",
    "print(country_values[:5])  # 0    Guinea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분리한 문자열을 status, country라는 열 이름으로 데이터프레임에 추가\n",
    "ebola_long['status'] = status_values\n",
    "ebola_long['country'] = country_values\n",
    "print(ebola_long.head())\n",
    "\n",
    "#          Date  Day      variable   value status country\n",
    "# 0    1/5/2015  289  Cases_Guinea  2776.0  Cases  Guinea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concat 메서드를 응용하여 데이터프레임에 열 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_split = ebola_long.variable.str.split('_', expand=True)  # expand: 여러 열을 한번에 다루기\n",
    "variable_split.columns = ['status', 'country']\n",
    "ebola_parsed = pd.concat([ebola_long, variable_split], axis=1)  # axis=1: 가로로 이어붙임\n",
    "print(ebola_parsed.head())\n",
    "\n",
    "#          Date  Day      variable   value status country status country\n",
    "# 0    1/5/2015  289  Cases_Guinea  2776.0  Cases  Guinea  Cases  Guinea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기상 데이터의 여러 열을 하나로 정리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv('../data/weather.csv')\n",
    "print(weather.iloc[:5, :])\n",
    "\n",
    "#         id  year  month element  d1    d2    d3  d4    d5  d6  ...  d22   d23  \\\n",
    "# 0  MX17004  2010      1    tmax NaN   NaN   NaN NaN   NaN NaN  ...  NaN   NaN  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day열에 날짜 열 정리, temp열에 날짜 열의 데이터 정리\n",
    "# 최고 최저 온도 눈에 잘 띄지 않음\n",
    "weather_melt = pd.melt(weather, id_vars=['id', 'year', 'month', 'element'], var_name='day', value_name='temp')\n",
    "print(weather_melt.head())\n",
    "\n",
    "#         id  year  month element day  temp\n",
    "# 0  MX17004  2010      1    tmax  d1   NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot_table메서드: 행과 열의 위치 다시 바꿈\n",
    "# index: 위치를 유지할 열이름 지정, columns: 피벗할 열 이름 지정, values: 새로운 열의 데이터가 될 열 이름 지정\n",
    "weather_tidy = weather_melt.pivot_table(\n",
    "index=['id', 'year', 'month', 'element'],\n",
    "columns='element',\n",
    "values='temp',\n",
    "dropna=False\n",
    ")\n",
    "print(weather_tidy)\n",
    "\n",
    "# element                          tmax       tmin\n",
    "# id      year month element                      \n",
    "# MX17004 2010 1     tmax     27.800000        NaN\n",
    "#                    tmin           NaN  14.500000\n",
    "#              2     tmax     27.750000        NaN\n",
    "#                    tmin           NaN  13.225000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임의 인덱스를 reset_index 메서드로 새로지정\n",
    "# weather_tidy의 인덱스를 새로 지정함.\n",
    "weather_tidy_flat = weather_tidy.reset_index()\n",
    "print(weather_tidy_flat.head())\n",
    "\n",
    "# element       id  year  month element       tmax    tmin\n",
    "# 0        MX17004  2010      1    tmax  27.800000     NaN\n",
    "# 1        MX17004  2010      1    tmin        NaN  14.500\n",
    "# 2        MX17004  2010      2    tmax  27.750000     NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 빌보드 차트의 중복 데이터 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard = pd.read_csv('../data/billboard.csv')\n",
    "billboard_long = pd.melt(billboard, id_vars=['year', 'artist', 'track', 'time', 'date.entered'], var_name='week', value_name='rating')\n",
    "\n",
    "print(billboard_long.shape)  # (24092, 7)\n",
    "print(billboard_long.head())\n",
    "#    year        artist                    track  time date.entered week  rating\n",
    "# 0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
    "# 1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1    91.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(billboard_long[billboard_long.track == 'Loser'].head())\n",
    "#       year        artist  track  time date.entered week  rating\n",
    "# 3     2000  3 Doors Down  Loser  4:24   2000-10-21  wk1    76.0\n",
    "# 320   2000  3 Doors Down  Loser  4:24   2000-10-21  wk2    76.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복되는 값을 가지고 있는 열을 따로 모아 새로운 데이터프레임에 저장\n",
    "billboard_songs = billboard_long[['year', 'artist', 'track', 'time']]\n",
    "print(billboard_songs.shape)  # billboard_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_songs = billboard_songs.drop_duplicates()\n",
    "print(billboard_songs.shape)  # (317, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복을 제거한 데ㅣ터프레임에 id추가\n",
    "billboard_songs['id'] = range(len(billboard_songs))\n",
    "print(billboard_songs.head(n=10))\n",
    "\n",
    "#    year          artist                    track  time  id\n",
    "# 0  2000           2 Pac  Baby Don't Cry (Keep...  4:22   0\n",
    "# 1  2000         2Ge+her  The Hardest Part Of ...  3:15   1\n",
    "# 2  2000    3 Doors Down               Kryptonite  3:53   2\n",
    "# 3  2000    3 Doors Down                    Loser  4:24   3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge메서드를 사용해 노래 정보와 주간순위데이터 합치기\n",
    "billboard_ratings = billboard_long.merge(billboard_songs, on=['year', 'artist', 'track', 'time'])\n",
    "        # billboard_long: 노래 정보\n",
    "print(billboard_ratings.shape)  # (24092, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴욕 택시 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 내려받기\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "with open('../data/raw_data_urls.txt', 'r') as data_urls:\n",
    "    for line, url in enumerate(data_urls):\n",
    "        if line == 5:\n",
    "            break\n",
    "        fn = url.split('/')[-1].strip()\n",
    "        fp = os.path.join('', '../data', fn)\n",
    "        print(url)\n",
    "        print(fp)\n",
    "        urllib.request.urlretrieve(url, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "nyc_taxi_data = glob.glob('../data/fhv_*')\n",
    "print(nyc_taxi_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi1 = pd.read_csv(nyc_taxi_data[0])\n",
    "taxi2 = pd.read_csv(nyc_taxi_data[1])\n",
    "taxi3 = pd.read_csv(nyc_taxi_data[2])\n",
    "taxi4 = pd.read_csv(nyc_taxi_data[3])\n",
    "taxi5 = pd.read_csv(nyc_taxi_data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(taxi1.head(n=2))\n",
    "print(taxi2.head(n=2))\n",
    "print(taxi3.head(n=2))\n",
    "print(taxi4.head(n=2))\n",
    "print(taxi5.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 연결\n",
    "taxi = pd.concat([taxi1, taxi2, taxi3, taxi4, taxi5])\n",
    "print(taxi.shape)  # (17367717, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 반복문으로 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_taxi_df = []\n",
    "\n",
    "for csv_filename in nyc_taxi_data:\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    list_taxi_df.append(df)\n",
    "\n",
    "print(len(list_taxi_df))  # 5\n",
    "\n",
    "print(type(list_taxi_df[0]))  # dataframe\n",
    "\n",
    "taxi_loop_concat = pd.concat(list_taxi_df)\n",
    "print(taxi_loop_concat.shape)  # (17367717, 3)\n",
    "\n",
    "print(taxi.equals(taxi_loop_concat))  # Ture\n",
    "    # 앞의 taxi에 저장된 데이터의 taxi_loop_concat에 저장한 데이터가 같은지 확인\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
